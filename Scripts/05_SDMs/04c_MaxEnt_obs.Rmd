---
title: "Maxent trained with observations"
author: "Denisse Fierro Arcos"
date: "2023-11-02"
output: 
  github_document:
    toc: true
    html_preview: false
---
# Maxent via SDMtune

MaxEnt is one of the most widely used species distribution model algorithm. 

In this project, we will use MaxEnt as one of the models to be considered in our Species Distribution Model ensemble to estimate the distribution of crabeater seals in the recent past.  
  
## Loading libraries

```{r, message=F, warning=F}
library(tidyverse)
library(SDMtune)
library(stars)
library(sf)
library(cmocean)
library(cowplot)
library(prg)
source("useful_functions.R")
```

## Setting up notebook

Selecting an output folder for GAM results exists and getting a list of data files.  
  
```{r}
#Location of folder for outputs
out_folder <- "../../SDM_outputs/Maxent/Obs"
#If folder does not exist, create one
if(!dir.exists(out_folder)){
  dir.create(out_folder, recursive = T)
}

#Get path to files containing data
file_list <- list.files("../../Environmental_Data/", pattern = "Indian", 
                        full.names = T)
```
   
## Loading environmental data from observations
We will use the datasets created in the notebook `02_Merging_background_presence_data.Rmd` located within the `Scripts/05_SDMs` folder. These datasets include the crabeater seal observations, background points, and environmental data.  
  
We will also define categorical and continuous explanatory variables.  
  
```{r}
#Loading data
obs_data <- read_csv(str_subset(file_list, "/obs.*VIF")) %>% 
  select(!c(sector, zone, season_year:decade)) %>% 
  #Setting month as factor and ordered factor
  mutate(month = as.factor(month)) %>% 
  drop_na()

covars <- str_subset(names(obs_data), "presence|_ocean", negate = T)
```
  
### Splitting data into testing and training
The `prep_data` function in the `useful_functions` script will be used to split our data and to apply all necessary transformations.
We will then transform the data into SWD ("samples with data") format, which is the required format for inputs used in the `SDMtune` library.   
   
```{r}
#Getting training data
obs_data <- prep_data(obs_data, "month", split = F)

#Applying SWD format to model data
model_data <- obs_data %>% 
  select(!year) %>% 
  sdm_format() %>% 
  trainValTest(test = 0.25, only_presence = T, seed = 42)
```
   
## Loading mean environmental conditions from observations

This dataset includes the mean environmental conditions per month (November and December) over the entire period of study (1981 to 2013).

```{r}
mean_obs <- read_csv("../../Environmental_Data/Env_obs/All_values_month_Obs_env_vars.csv") %>% 
  mutate(month = as.factor(month)) %>% 
  #Drop variables with high multicollinearity
  select(ends_with("_ocean")|any_of(covars))

mean_obs_baked <- prep_pred(mean_obs, "month")
```
  
## Loading layers for plotting
We will extract this layer from the `rnaturalearth` package. We will then reproject this layer to South Polar Stereographic (`EPSG 3976`).  
  
```{r}
#Loading layer
antarctica <- rnaturalearth::ne_countries(continent = "Antarctica",
                                          returnclass = "sf") %>% 
  #Transforming to South Polar Stereographic
  st_transform(3976)
```
  
## Modelling
MaxEnt has different feature classes (`fc`, otherwise known as restrictions) available for modelling. These `fc` include:  
- `l` - lineal,  
- `q` - quadratic,  
- `p` - product,  
- `t` - threshold,  
- `h` - hinge  
and any possible combination of these 5 features.  
  
Regularisation (`reg`) refers to *L1 regularisation* also known as *Lasso (Least Absolute Shrinkage and Selection Operator) regression*. This involves adding an absolute value of magnitude as a penalty term to the loss function. It is used to prevent overfitting. In MaxEnt a `reg` value lower than 1 results in a outputs that fit closer to presence data. The risk of using values that are too small is a model that overfits and therefore does not generalised well. While, `reg` values larger than 1 result in less localised predictions, producing smoother or more diffuse distributions.  
  
Here, we use the `SDMtune` library to test various value combinations for regularisation, feature classes and number of iterations. We will identify the "best model" using the `AUC` for the testing dataset.  
  
```{r, eval = FALSE}
#Train model
default_model <- train(method = "Maxent", data = model_data[[1]])

# Define the hyperparameters to test
hyp_parm <- list(reg = seq(0.5, 5, 0.5),
                 #Feature classes
                 fc = c("lq", "lh", "lqp", "lqph", "lqpht"),
                 #Number of iterations
                 iter = c(500, 1000, 1500))

# Test all the possible combinations with gridSearch
gs_obs <- optimizeModel(default_model, hypers = hyp_parm, metric = "auc", 
                        test = model_data[[2]], seed = 42)

#Check best performing models based on AUC
gs_obs@results %>% 
  #Adding index as column to identify best model easily
  rownames_to_column("index") %>% 
  #Arranging results by AUC from testing data (descending order)
  arrange(-test_AUC) %>% 
  #Showing only the top 5 models
  head(n = 5)

#Best model based on test AUC and smallest AUC difference between train and test
best_max_obs <- gs_obs@models[[1]]

out <- file.path(out_folder, "initial_Maxent_model")
#If folder does not exist, create one
if(!dir.exists(out)){
  dir.create(out, recursive = T)
}

#Save best performing model to disk to avoid having to tune model again
best_max_obs %>% 
  saveRDS(file.path(out, "best_maxent_obs_grid.rds"))
```
  
```{r, echo = F}
#Loading best initial model to avoid performing grid search of parameters
best_max_obs <- file.path(out_folder, 
                          "initial_Maxent_model/best_maxent_obs_grid.rds") %>% 
  readRDS()
```
  
  
## Variable importance
We will check the contribution of each environmental variable to the model performance.  
  
```{r}
#Calculating importance
var_imp_best <- varImp(best_max_obs) 

#Plotting results
p <- var_imp_best %>% 
  plotVarImp()

p
```
  
Sea ice concentration (`SIC`) is the variable with the highest importance in this model, and its about twice as important as the sea surface temperature (`SST_degC`), which was the second most important variable.
  
Both `month` and the slope of the seafloor (`bottom_slope_deg`) contribute less than 5% each to the model, so we may be able to drop these without affecting overall model performance.
  
## Jacknife tests
We can now check which variables contributed the most to this model.
  
```{r}
jk_obs <- doJk(best_max_obs, metric = "auc", test = model_data[[2]])
jk_obs
```
  
### Plotting Jacknife results

```{r}
plotJk(jk_obs, type = "train", ref = SDMtune::auc(best_max_obs))
```
  
When used on their own, `SIC`, `SST_degC` and distance to the sea ice edge (`dist_ice_edge_km`) contribute the most to model performance. Their removal affects performance negatively. While `month` and `bottom_slope_deg` contribute the least and their removal has almost no impact.    
   
```{r}
plotJk(jk_obs, type = "test", ref = SDMtune::auc(best_max_obs, 
                                                 test = model_data[[2]]))
```
  
Results from the training dataset are pretty similar. We can check if we are able to remove `bottom_slope_deg` and `month` from the model without affecting performance.  
  
## AUC curves 
We will calculate AUC curves, so we can compare to the simplified models we will test.  
  
```{r}
plotROC(best_max_obs, test = model_data[[2]])
```
  
## True Skill Statistic (TSS)

```{r}
tss(best_max_obs)
```
  
This model is not a good performer.  
  
## Model report
Before moving onto testing a new model, we will save a report with the information shown above.  
  
```{r, eval=F}
modelReport(best_max_obs, type = "cloglog", 
            folder = file.path(out_folder, "initial_Maxent_model"),
            test = model_data[[2]], response_curves = T, only_presence = T, 
            jk = T)
```
  
## Reducing model variables
As discussed above, there are some variables that do not contribute much to the model performance, such as `month` and the slope of the seafloor (`bottom_slope_deg`). We will check here if we are able to exclude them without negatively impacting performance.  
  
We will use 10% as a threshold, but we will only exclude variables if they do not decrease model performance.  
  
```{r}
simple_model <- reduceVar(best_max_obs, metric = "auc", test = model_data[[2]],
                          th = 10, permut = 10, use_jk = T)

simple_model
```
  
As suspected, `month` and the slope of the seafloor (`bottom_slope_deg`) can be excluded from our model.Now, we will fitted the model again to find the best hyperparameter values.  
  
## Training model with reduced variables
  
```{r, eval = F}
#Select variables
model_data_simple <- obs_data %>% 
  select(!c(year, month, bottom_slope_deg)) %>% 
  sdm_format() %>% 
  trainValTest(test = 0.25, only_presence = T, seed = 42)

#Train model
default_model <- train(method = "Maxent", data = model_data_simple[[1]])

# Test all the possible hyper parameter combinations with gridSearch
gs_mod <- optimizeModel(default_model, hypers = hyp_parm, metric = "auc", 
                        test = model_data_simple[[2]], seed = 42)

#Check best performing models based on AUC
gs_mod@results %>% 
  #Adding index as column to identify best model easily
  rownames_to_column("index") %>% 
  #Arranging results by AUC from testing data (descending order)
  arrange(-test_AUC) %>% 
  #Showing only the top 5 models
  head(n = 5)

#Best model based on test AUC and smallest AUC difference between train and test
best_max_mod <- gs_mod@models[[1]]

out <- file.path(out_folder, "reduced_Maxent_model")
#If folder does not exist, create one
if(!dir.exists(out)){
  dir.create(out, recursive = T)
}

best_max_mod %>% 
  saveRDS(file.path(out, "best_red_maxent_model.rds"))
```
  
The only hyperparameter changed was the number of iterations. We will save a report for this model.  
  
```{r, echo = F}
#Select variables
model_data_simple <- obs_data %>% 
  select(!c(year, month, bottom_slope_deg)) %>% 
  sdm_format() %>% 
  trainValTest(test = 0.25, only_presence = T, seed = 42)

#Loading best initial model to avoid performing grid search of parameters
best_max_mod <- file.path(out_folder, 
                          "reduced_Maxent_model/best_red_maxent_model.rds") %>% 
  readRDS()
```
  
## Variable importance
  
```{r, eval=F}
#Calculating variable contribution based on permutations
var_imp_best <- varImp(best_max_mod) 

#Plotting results
p <- var_imp_best %>% 
  plotVarImp()

saveRDS(p, "../../SDM_outputs/Maxent/Maxent_var_imp_obs.rds")
```
  
```{r, echo = FALSE}
p <- readRDS("../../SDM_outputs/Maxent/Maxent_var_imp_obs.rds")
p
```
  
## Model report

```{r, eval = F}
#Produce report
modelReport(best_max_mod, type = "cloglog", folder = out, 
            test = model_data_simple[[2]], 
            response_curves = T, only_presence = T, jk = T)
```
  
## AUC curves 
We will calculate AUC curves, so we can compare to the simplified models we will test.  
  
```{r}
plotROC(best_max_mod, test = model_data_simple[[2]])
```
  
## True Skill Statistic (TSS)

```{r}
tss(best_max_mod)
```
  
## Performance metrics
To be able to compare the performance of this model with the three other SDM algorithms to be used in the SDM ensemble, we will calculate three metrics: area under the receiver operating curve ($AUC_{ROC}$), area under the precisison-recall gain curve ($AUC_{PRG}$) and the Pearson correlation between the model predictions and the testing dataset.  
  
```{r, eval = F}
#Predicting values using testing dataset
pred <- predict(best_max_mod, model_data_simple[[2]]@data, type = "cloglog")

#AUC ROC
auc_roc <- SDMtune::auc(best_max_mod, model_data_simple[[2]])

#AUC PRG
auc_prg <- create_prg_curve(model_data_simple[[2]]@pa, pred) %>% 
  calc_auprg()

#Pearson correlation
cor <- cor(pred, model_data_simple[[2]]@pa)

print(c(paste0("AUC ROC: ", round(auc_roc, 3)),
        paste0("AUC PRG: ", round(auc_prg, 3)),
        paste0("Pearson correlation: ", round(cor, 3))))
```  
  
Saving model evaluation results.   
  
```{r, eval = F}
#Load model evaluation data frame and add results
model_eval_path <- "../../SDM_outputs/model_evaluation.csv"
read_csv(model_eval_path) %>% 
  bind_rows(data.frame(model = "Maxent", env_trained = "observations", 
                       auc_roc = auc_roc, auc_prg = auc_prg, 
                       pear_cor = cor)) %>% 
  write_csv(model_eval_path)
```
  

## Predictions
We will use this reduced Maxent model to predict the distribution of crabeater seals.  
  
```{r eval = F}
pred_obs <- mean_obs_baked %>% 
  drop_na() %>% 
  mutate(pred = as.vector(predict(best_max_mod,
                                  data = drop_na(mean_obs_baked),
                                  type = "cloglog")))

pred_obs_ras <- pred_obs %>% 
  #Select relevant variables only
  select(xt_ocean, yt_ocean, pred, month) %>% 
  right_join(mean_obs_baked %>%
  #Select relevant variables only
  select(xt_ocean, yt_ocean, month)) %>% 
  #Set dimensions
  st_as_stars(dims = c("xt_ocean", "yt_ocean", "month")) %>% 
  #Ensuring month dimension is shown correctly
  st_set_dimensions("month", values = c(11, 12)) %>%
  #Set CRS
  st_set_crs(4326) %>% 
  #Transform to South Pole stereographic
  st_transform(crs = st_crs(3976))

#Saving outputs
#Data frame
pred_obs %>% 
  write_csv(file.path(out, "mean_pred_obs.csv"))
#Saving as R dataset so it can be easily open with readRDS
saveRDS(pred_obs_ras,
        file.path(out, "mean_pred_obs_raster.rds"))
```

## Plotting predictions

```{r, eval = F}
#Plotting November distribution
#Prepping data
nov <- pred_obs_ras %>% 
  slice(index = 1, along = "month") 

#Plotting
nov_plot <- ggplot()+
  geom_stars(data = nov)+
  geom_sf(data = antarctica)+
  lims(x = c(0, 4000000))+
  #Set colour palette
  scale_fill_cmocean(name = "haline", direction = -1, 
                     guide = guide_colorbar(barwidth = 1, barheight = 10, 
                                            ticks = FALSE, nbin = 1000, 
                                            frame.colour = "black"), 
                     limits = c(0, 1)) +
  theme_linedraw() +
  theme(panel.background = element_blank(),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(), 
        legend.position = "none",
        plot.title = element_text(hjust = 0.5)) +
  labs(title = "November",
       x = "Longitude",
       y = "Latitude")

dec <- pred_obs_ras %>% 
  slice(index = 2, along = "month") 

dec_plot <- ggplot() +
  geom_stars(data = dec) +
  geom_sf(data = antarctica)+
  lims(x = c(0, 4000000))+
  scale_fill_cmocean(name = "haline", direction = -1, 
                     guide = guide_colorbar(barwidth = 1, barheight = 10, 
                                            ticks = FALSE, nbin = 1000, 
                                            frame.colour = "black"), 
                     limits = c(0, 1)) +
  theme_linedraw() +
  theme(panel.background = element_blank(),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(), 
        plot.title = element_text(hjust = 0.5)) +
  labs(title = "December",
       x = "Longitude",
       y = " ",
       fill = "Probability")

#Get legend
legend <- get_legend(dec_plot)

#Remove legend from December plot
dec_plot <- dec_plot + theme(legend.position = 'none')

#Plotting together
plot_obs <- plot_grid(nov_plot, dec_plot, legend, ncol = 3, nrow = 1,
                            rel_widths = c(1, 1, 0.3))

#Add title
title <- ggdraw()+
  draw_label("Mean crabeater seal distribution\n(observations)",
             fontface = "bold", hjust = 0.5)+
  theme(plot.margin = margin(0, 0, 0, 0))

#Putting everything together
final <- plot_grid(title, plot_obs, ncol = 1, 
          rel_heights = c(0.1, 1))

#Saving graph
ggsave(file.path(out_folder, "map_mean_pred_obs.png"), plot = final, 
       device = "png", bg = "white", width = 8.75, height = 7)

```
  
